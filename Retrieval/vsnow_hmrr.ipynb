{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snowfall retrieval \n",
    "vsnow_hmrr.pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The retrieval uses the following:\n",
    "\n",
    "    - RR:           true rainrate profile from input file\n",
    "    - rainrate:     retrieved rainrate profile\n",
    "    - rainrate_a:   a priori guess at rainrate (set to 5.0 mm/hr)\n",
    "    \n",
    "    - y_obs:        observed reflectivities\n",
    "    - y_sim:        simulated refelectivities\n",
    "    \n",
    "    - S_a_matrix:   a priori error covariance matrix\n",
    "    - S_y_matrix:   measurement error covariance matrix\n",
    "    - S_x_matrix:   retrieval error covariance matrix\n",
    "    \n",
    "    - K_matrix:     matrix of Kernel functions\n",
    "    - A_matrix:     averaging Kernel\n",
    "    \n",
    "    - y_contrib:    measurement contribution matrix (Dy Sy Dy^T)\n",
    "    - a_contrib:    a priori contribution matrix (Da Sa Da^T)\n",
    "    - LWP_contrib:  LWP contribution matrix (D_LWP sigma_LWP^2 DLWP^T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Volumes/SANDISK128/Documents/Thesis/Python/')\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import createFolder as cF\n",
    "import save_fig as SF\n",
    "import math\n",
    "import scipy.constants as const\n",
    "\n",
    "import sub24hnum as sub\n",
    "import read_MRR as pMRR\n",
    "import calc_date as cd\n",
    "%matplotlib inline\n",
    "from decimal import *\n",
    "getcontext().prec = 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_blue = np.array([1,74,159])/255.    \n",
    "def plt_refl(ax0, time_MRR, height_MRR, Ze, calday, day, calmon, year):\n",
    "    levels = np.arange(-10,30,0.2)\n",
    "    CS = ax0.contourf(time_MRR, height_MRR , Ze, \n",
    "                  levels, cmap='jet')\n",
    "# add colorbar\n",
    "    cbaxes = fig.add_axes([0.14, 0.1, .75, .02] )   #[left, bottom, width, height] \n",
    "    cbar = plt.colorbar(CS, orientation = 'horizontal', cax=cbaxes)\n",
    "    cbar.ax.set_xlabel('MRR reflectivity [dBz]', fontsize = 22)\n",
    "    cbar.ax.tick_params(labelsize = 20)\n",
    "\n",
    "# labels\n",
    "    times = [0, 3, 6, 9,12, 15, 18, 21, 24]\n",
    "    ax0.set_xticks(np.arange(0,60*60*25,3*60*60))\n",
    "    ax0.set_xticklabels(times, fontsize = 20)\n",
    "    ax0.set_xlabel('time [hours]', fontsize = 22)\n",
    "\n",
    "    ax0.set_ylabel('height [km]', fontsize = 22)\n",
    "    ax0.set_ylim(0,3.5)\n",
    "    ax0.set_yticks(np.arange(0,3500.,500.))\n",
    "    yl = [0., '' , 1.0, '' , 2., '' , 3.]\n",
    "    ax0.set_yticklabels(yl, fontsize = 20)\n",
    "    \n",
    "    \n",
    "# textbox\n",
    "    ax0.text(0.02,0.96, '%s, %s %s %s' %(calday, day, calmon, year), verticalalignment = 'top',  \n",
    "         horizontalalignment='left',\n",
    "             transform = ax0.transAxes,\n",
    "            color =date_blue, fontsize=30,\n",
    "           bbox={'facecolor':'white','alpha':1., 'pad':10})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = '2016'\n",
    "mon = '12'\n",
    "day = '23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calday, calmon = cd.get_dayname(year,mon, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfig = 0\n",
    "fig_dir = '../../Figures/Retrieval/'\n",
    "cF.createFolder(fig_dir)\n",
    "form = 'png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### 200m, processed MRR file ########################################\n",
    "MRR_dir = '../../Data/MRR/processed_MRR/'\n",
    "fnMRR = netCDF4.Dataset('%s/VMRR_%s%s%s.nc' %(MRR_dir,year,mon,day) ,'r')\n",
    "\n",
    "time_MRR = fnMRR.variables['time'][:]\n",
    "height_MRR = fnMRR.variables['height'][:]\n",
    "\n",
    "Ze = pMRR.read_and_mask(fnMRR,'Ze', np.nan)         # vertical Ze profile for retrieval\n",
    "Ze.astype(np.float32)\n",
    "W = pMRR.read_and_mask(fnMRR, 'mean_doppler_velocity', np.nan)    # Doppler data for fallspeed analyses\n",
    "W = (W) * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#################################################################################################\n",
    "######## the following is not in the retrieval ##################   \n",
    "######## plot MRR reflectivity ##################################\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "gs = gridspec.GridSpec(7,1)\n",
    "ax0 = fig.add_subplot(gs[:6,:])\n",
    "plt_refl(ax0, time_MRR, height_MRR, np.transpose(Ze), calday, day, calmon, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_kazr = Ze.shape[0]         # 1440, number of radar profiles\n",
    "nlayers = Ze.shape[1]          # 14, every 200m\n",
    "nx = nlayers + nlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### processed MetNo, temperature file ########################################\n",
    "temp_dir = '../../Data/sfc_temp/nc'\n",
    "fnT = netCDF4.Dataset('%s/Haukeli_sfc_temp_%s%s%s.nc' %(temp_dir,year,mon,day),'r')\n",
    "\n",
    "time_temp = fnT.variables['time'][:].astype(np.float32)        # stime ...surface time\n",
    "sfc_temp = fnT.variables['sfc_temp'][:].astype(np.float32)    # stemp ...surface temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntemp = sfc_temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### define values ###########################\n",
    "# line 83:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bad = 0.\n",
    "# line 112:\n",
    "#### START RETRIEVAL LOOP ###########################\n",
    "#for icol2 in range(0,num_kazr):\n",
    "# line 111:\n",
    "#    print(icol2)\n",
    "\n",
    "# line 125:\n",
    "# surftemp = stemp(icol2)\n",
    "# vmax = max(vdop(icol2,0:5))\n",
    "# v4 = max(y_obs)\n",
    "# if (v4 gt -15.0 and surftemp lt 2.0) then begin      ; Ze mask to save time if no snow\n",
    "# else begin\n",
    "# goto, skipend\n",
    "\n",
    "# line 149:\n",
    "# constraint_flag = 0              ; Set to 1 to use LWP constraint\n",
    "\n",
    "# line 160:\n",
    "# pi = 3.141592653\n",
    "# comment = ''\n",
    "# maxiter = 10                     ; Maximum number of iterations\n",
    "# perturbations = 0.2              ; % value to perturb the retrieved rainrate in calculation of the K-matrix\n",
    "# delta_Z = 200.                   ; Layer thickness in m\n",
    "\n",
    "# line 172:\n",
    "# nprofiles = 1\n",
    "# nrequencies = 1\n",
    "\n",
    "# line 199:\n",
    "# bad_rainrate_flag = 0\n",
    "\n",
    "# line 275:\n",
    "# tguess = stemp(icol2)+273\n",
    "# for ilapse = 0, nlayers-1 do begin\n",
    "#     t_apriori(ilapse) = tguess-1.*float(ilapse)          ;  ~ moist adiabat 5K/km 1K/200m\n",
    "# endfor; ilapse\n",
    "\n",
    "# line 282:\n",
    "# for iss = 0, nlayers-1 do begin\n",
    "#    ap_slp(iss)= -(0.03053)*(t_apriori(iss)-273.0)-0.08258         ; a priori log(lambda,ap)\n",
    "#    ap_n0(iss)=  -(0.07193)* (t_apriori(iss)-273)+2.665            ; a priori log(N0,ap)\n",
    "#    endfor; iss\n",
    "\n",
    "# line 303:\n",
    "# for nkbins=0, nlayers-1 do begin\n",
    "#    slp(nkbins)=ap_slp(nkbins)\n",
    "# endfor; nkbins\n",
    "# for nkbins=nlayers, nx-1 do begin\n",
    "#    slp(nkbins)=ap_n0(nkbins-nlayers)\n",
    "# endfor; nkbins\n",
    "\n",
    "# line 314:\n",
    "# for i=0, nlayers-1 do begin\n",
    "#    slpa(i) = ap_slp(i)\n",
    "# for i=nlayers, nx-1 do begin\n",
    "#    slpa(i) = ap_n0(i-nlayers)\n",
    "\n",
    "# line 325:\n",
    "# for i=0,nlayers-1 do begin\n",
    "#    Symatrix(i,i) = (2.5)^2       ; 2 dBz\n",
    "# for i=0, nlayers-1 do begin\n",
    "#    Samatrix(i,i) = 0.133         ; from Wood et al.\n",
    "# for i=nlayers, nx-1 do begin\n",
    "#    Samatrix(i,i) = 0.95\n",
    "\n",
    "# line 339:\n",
    "# for iter=0,maxiter-1 do begin\n",
    "#    print,' '\n",
    "#    print,'Iteration:',iter+1\n",
    "\n",
    "# line 345:\n",
    "# upperturb = slp\n",
    "# downperturb=slp\n",
    "# for i= 0 , nx-1 do begin\n",
    "#    upperturb(i)   = slp(i)*(1.0 + perturbation/100.0)\n",
    "#    downperturb(i) = slp(i)*(1.0 - perturbation/100.0)\n",
    "\n",
    "# line 358:\n",
    "# sub24hnum, upperturb, y_max, iwcpsd, nlayers, delta_z\n",
    "# sub24hnum, downperturb, y_min, iwcpsd, nlayers, delta_z\n",
    "\n",
    "# line 363:\n",
    "# for j=0,nlayers-1 do begin\n",
    "# Kmatrix(i,j) = (y_max(j)-y_min(j))/(upperturb(i)-downperturb(i))\n",
    "\n",
    "# line 375:\n",
    "# sub24hnum, slp, y_sim, iwcpsd, nlayers, delta_z\n",
    "\n",
    "# line 399:\n",
    "# if(constraint_flag eq 0) then begin\n",
    "#     Sxmatrix = invert(invert(Samatrix) + transpose(Kmatrix)##invert(Symatrix)##Kmatrix)\n",
    "#     slp      = Sxmatrix##(invert(Samatrix)##slpa + transpose(Kmatrix)##invert(Symatrix)##(y_obs - y_sim + Kmatrix##slp))\n",
    "# endif else begin\n",
    "#    Sxmatrix = invert(invert(Samatrix) + transpose(Kmatrix)##invert(Symatrix)##Kmatrix + delta_Z^2*transpose(L)##L/sigma_LWP^2)\n",
    "#    slp      = Sxmatrix##(invert(Samatrix)##slpa + transpose(Kmatrix)##invert(Symatrix)##(y_obs - y_sim + Kmatrix##slp) + delta_Z*transpose(L)*(LWP_obs - LWP_sim)/sigma_LWP^2 + delta_Z^2*transpose(L)##L##slp/sigma_LWP^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_snow = []\n",
    "bad = 0.0\n",
    "## line 112:\n",
    "#### START RETRIEVAL LOOP ###########################\n",
    "for icol2 in range(0,num_kazr):\n",
    "#for icol2 in range(0,1):\n",
    "    print('icol2',icol2)\n",
    "#### DEFINE VALUES ###########################\n",
    "    t_apriori    = np.zeros(shape=nlayers, dtype=np.float32)\n",
    "    \n",
    "    slp          = np.zeros(shape=nx,dtype=np.float32)                     # retrieval vector  ??? same as ap_slp, ap_N0\n",
    "    slpa         = np.zeros(shape=nx,dtype=np.float32)\n",
    "    \n",
    "    S_y_matrix   = []                     # measurement error covariance matrix;\n",
    "    S_a_matrix   = []                     # a priori error covariance matrix;\n",
    "    \n",
    "    up_perturb   = np.zeros(shape=nx,dtype=np.float32)\n",
    "    down_perturb = np.zeros(shape=nx,dtype=np.float32)\n",
    "    y_max        = np.zeros(shape=nlayers,dtype=np.float32)\n",
    "    y_min        = np.zeros(shape=nlayers,dtype=np.float32)\n",
    "    y_sim        = np.zeros(shape=nlayers,dtype=np.float32)\n",
    "    IWC_psd      = np.zeros(shape=nlayers,dtype=np.float32)\n",
    "    K_matrix     = np.zeros(shape=(nx,nlayers),dtype=np.float32)\n",
    "    \n",
    "    slp_temp     = np.zeros(shape=nx,dtype=np.float32)\n",
    "    \n",
    "    S_x_matrix   = np.zeros(shape=(nx,nx),dtype=np.float32)     # retrieval error covariance matrix\n",
    "##############################################\n",
    "\n",
    "#### READ IN VALUES ###########################\n",
    "    y_obs = Ze[icol2, :].astype(np.float32)                # vertical Ze profile for retrieval, observed reflectivities\n",
    "    yobs = Ze[:,:].astype(np.float32)                      # Ze(time, profiles) for plots\n",
    "    vdop = W[:,:].astype(np.float32)                       # get Doppler data for fallspeed analyses\n",
    "##############################################\n",
    "\n",
    "#### VALID VALUES ZE> -15, SURFACE TEMP < 2 ###########################\n",
    "## line 125:    \n",
    "#    surftemp = sfc_temp[icol2]\n",
    "    vmax = np.nanmax(vdop[icol2,0:6])\n",
    "\n",
    "#    snow = np.nanmax(y_obs)\n",
    "    if (np.nanmax(Ze[icol2, :]) > -15. and sfc_temp[icol2] < 2.):      # ; Ze mask to save time if no snow, then go to the next Ze profile\n",
    "        idx = np.where(np.logical_and(Ze[icol2, :] > -15., sfc_temp[icol2]< 2.))\n",
    "        h_snow.append(400.)\n",
    "##### in retrieval without h_snow ##########    \n",
    "    else:\n",
    "        h_snow.append(np.nan)\n",
    "        continue\n",
    "##############################################\n",
    "\n",
    "\n",
    "\n",
    "#### NOISE/ERROR PARAMETERS ###########################       \n",
    "## line 149:     \n",
    "    constrain_flag    = 0                  # set to 1 to use LWP constraint\n",
    "#### OTHER INPUT PARAMETERS (shouldn't need to be changed for the project) ###########################       \n",
    "## line 160:\n",
    "    pi                = const.pi\n",
    "    comment           = ''\n",
    "    max_iter          = 10                  # maximum number of iterations\n",
    "    perturbation      = 0.2                 # % value to perturb the retrieved rainrate in calculation of the K-matrix\n",
    "    delta_z           = 200.                # layer thickness in m\n",
    "## line 172:\n",
    "    nprofiles         = 1\n",
    "    nrequencies       = 1\n",
    "## line 199:\n",
    "    bad_rainrate_flag = 0\n",
    "##############################################\n",
    "\n",
    "\n",
    "#### DEFINE A PRIORI VALUES VIA WOOD ET AL PAPER PAGE 7 ###########################\n",
    "## line 275:\n",
    "    tguess = sfc_temp[icol2]+273.\n",
    "    for ilapse in range(0,nlayers):\n",
    "        t_apriori[ilapse] = (tguess - 1. * ilapse)               # ~moist adiabat 5K/km 1K/200m\n",
    "##############################################\n",
    "\n",
    "\n",
    "#### DEFINE A PRIORI PSD INFO (LOG FORM) THROUGH WOOD TEMPERATURE PARAMETERIZATION ###########################\n",
    "## line 282:\n",
    "    ap_slp       = np.zeros(shape = nlayers,dtype=np.float32)\n",
    "    ap_N0        = np.zeros(shape = nlayers,dtype=np.float32)\n",
    "    for iss in range(0, nlayers):\n",
    "        ap_slp[iss] = (-0.03053*(t_apriori[iss]-273.0)-0.08258)          # a priori log(lambda,ap))\n",
    "        ap_N0[iss]  = ( -0.07193*(t_apriori[iss]-273.0)+2.665 )           # a priori log(N0,ap))\n",
    "##############################################\n",
    "\n",
    "#### DEFINE INITIAL GUESS FOR RETRIEVAL VECTOR (PSD INFORMATION) THROUGH A PRIORI GUESS ###########################\n",
    "## line 303:\n",
    "    for nkbins in range(0,nlayers):\n",
    "        slp[nkbins] = (ap_slp[nkbins])\n",
    "    \n",
    "    for nkbins in range(nlayers, nx):\n",
    "        slp[nkbins] = (ap_N0[nkbins-nlayers])\n",
    "##############################################\n",
    "\n",
    "#### RE-WRITE APRIORI TERMS (ap_slp, ap_N0) INTO A PRIORI TERM 'slpa' ###########################\n",
    "#    for i in range(0,nlayers):           # same as before --> rename slp to slpa\n",
    " #       slpa.append(ap_slp[i])\n",
    "  #  for i in range(nlayers, nx):\n",
    "   #     slpa.append(ap_N0[i-nlayers])\n",
    "    #print(pd.DataFrame([slp, slpa]))\n",
    "    slpa = slp\n",
    "##############################################\n",
    "\n",
    "\n",
    "#### SET-UP Sy (FORWARD MODEL AND INSTRUMENT UNCERTAINTIES) AND ###########################\n",
    "#### Sa (A PRIORI) ERROR COVARIANCE MATRICES ###########################\n",
    "    for i in range(0,nlayers):\n",
    "        S_y_matrix.append([0] * nlayers)  \n",
    "    for i in range(0, nx):\n",
    "        S_a_matrix.append([0] * nx)\n",
    "    for i in range(0,nlayers):                      \n",
    "        S_y_matrix[i][i] = 2.5**2                             # 2dBz  \n",
    "        S_a_matrix[i][i] = 0.133                              # from Wood et al.\n",
    "    for i in range(nlayers,nx):\n",
    "        S_a_matrix[i][i] = 0.95\n",
    "        \n",
    "    S_y_matrix = (np.asarray(S_y_matrix).astype(np.float32))\n",
    "    S_a_matrix = (np.asarray(S_a_matrix).astype(np.float32))\n",
    "##############################################\n",
    "\n",
    "        \n",
    "\n",
    "#### NOW BEGIN RETRIEVAL LOOP ###########################\n",
    "    for iteration in range(0, max_iter):\n",
    "#    for iteration in range(0, 1):\n",
    "        print('')\n",
    "        print('Iteration:', iteration+1)\n",
    "        \n",
    "        \n",
    "#### COMPUTE THE SENSITIVITY MATRIX, K, THROUGH PERTURBING RETRIEVAL VECTOR ###########################\n",
    "        for i in range(0, nx):\n",
    "            up_perturb[i]   = ((slp[i]) * (1. + perturbation/100.))\n",
    "            down_perturb[i] = ((slp[i]) * (1. - perturbation/100.))\n",
    "##############################################\n",
    "        \n",
    "\n",
    "#### CALL FORWARD MODEL FOR PERTURBATIONS ###########################\n",
    "        for i in range(0, nx):\n",
    "#        for i in range(0,2):\n",
    "            print('i',i)\n",
    "            y_max, IWC_psd = sub.sub24hnum(up_perturb, nlayers, delta_z)\n",
    "#            print('ymax',y_max)#, 'IWC_psd',IWC_psd)\n",
    " #           print('up_perturb', up_perturb)\n",
    "            y_min, IWC_psd= sub.sub24hnum(down_perturb, nlayers, delta_z)\n",
    " #           print('ymin',y_min)#, 'IWC_psd',IWC_psd)\n",
    "   #         print('down_perturb',down_perturb)\n",
    "            \n",
    "\n",
    "# line 363:\n",
    "            for j in range(0,nlayers):\n",
    "    #            print('y_diff',y_max[j] - y_min[j])\n",
    "     #           print('perturp_diff',up_perturb[i]-down_perturb[i])\n",
    "                K_matrix[i,j] = (y_max[j] - y_min[j])/(up_perturb[i]-down_perturb[i])   # matrix of Kernel functions\n",
    "          #  print(K_matrix)    \n",
    "            up_perturb[i]   = slp[i]\n",
    "            down_perturb[i] = slp[i]  \n",
    "##############################################\n",
    "\n",
    "#### CALL FORWARD MODEL FOR Y_SIM ###########################\n",
    "# line 375:\n",
    "        y_sim, IWC_psd = sub.sub24hnum(slp, nlayers, delta_z)\n",
    "##############################################\n",
    "\n",
    "#### PERFORM RETRIEVAL ###########################\n",
    "# line 399:\n",
    "#        if constrain_flag == 0:\n",
    " #           S_x_matrix = np.linalg.inv( np.linalg.inv(S_a_matrix) + (np.matmul(np.transpose(K_matrix), np.linalg.inv(S_y_matrix)), K_matrix ))\n",
    "  #          print(S_x_matrix)\n",
    "##############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def sub24hnum(slp2,nbin,dz):\n",
    "    txt_dir = '../../Retrieval/unchanged/part_scat_forward_model'\n",
    "\n",
    "## readfile='B6pr_2_dimensional_and_mass_oriented_24.0GHz.txt'\n",
    "    model = 'B6pr_2_dimensional_and_mass_oriented_24.0GHz.txt'\n",
    "\n",
    "## readfile='readfile='SP_dimensional_and_mass_oriented_24.0GHz.txt'\n",
    "#model = 'SP_dimensional_and_mass_oriented_24.0GHz.txt'\n",
    "\n",
    "## readfile='HC_dimensional_and_mass_oriented_24.0GHz.txt'\n",
    "#model = 'HC_dimensional_and_mass_oriented_24.0GHz.txt'\n",
    "\n",
    "\n",
    "#### READ IN SCATTERING MODEL ###########################\n",
    "# readfile='B6pr_2_dimensional_and_mass_oriented_24.0GHz.txt'\n",
    "    scat_mod = pd.read_csv('%s/%s' %(txt_dir,model),\\\n",
    "                    header=3,  names = ['r_ev','mass', 'C_bk', 'C_sca', 'C_ext', 'Ldim','none'], \\\n",
    "                    sep = '\\s+', engine= 'python')\n",
    "##############################################\n",
    "\n",
    "\n",
    "# line 22:\n",
    "# Rayleigh approximation?:\n",
    "    radar_freq = 24.0e9                  # radar frequency in [Hz]\n",
    "    Pi         = const.pi                        # Pi\n",
    "    c          = const.speed_of_light             # speed of light in [m/s]\n",
    "    K_sq_water = 0.92                    # dielectric factor abs(K)^2_liquid = 0.92       (AOS740 7-9)\n",
    "    wavel_mm   = (c/radar_freq) * 1000.    # wavelength, lambda in [mm] \n",
    "\n",
    "# line 30 & line 51: \n",
    "#### READ IN BASE PARTICLE PROPERTIES ###########################\n",
    " #   Ldim   = scat_mod['Ldim']/1000.          # [um]\n",
    "    r_ev   = scat_mod['r_ev']/1000.    # effective radius [um] --> [mm]\n",
    "    Ldim   = scat_mod['r_ev']/1000.    # [mm]\n",
    "    C_bk   = scat_mod['C_bk']          # backscatter coefficient [m^2]\n",
    "#C_ext = scat_mod['C_ext']        # extinction coefficient [m^2]\n",
    "    C_scat = scat_mod['C_sca']         # scattering coefficient [m^2]\n",
    "    mass   = scat_mod['mass']*1000.    # mass [kg]  -->\n",
    "#area = scat_mod['Ldim']          # [um]\n",
    "#maxd = \n",
    "##############################################\n",
    "    nd = r_ev.shape[0]\n",
    "## in retrieval:\n",
    "    C_ext = C_scat\n",
    "    \n",
    "    \n",
    "#### MAKE SIMPLE log PSD ###########################\n",
    "# line 74:\n",
    "    lamb = np.zeros(shape = nbin)\n",
    "    N0   = np.zeros(shape = nbin)\n",
    "    numd = np.zeros(shape = nd)\n",
    "# for k=0, 0  do begin     ; each vertical profile\n",
    "    for k in range(0,1):\n",
    "        IWC_psd  = np.zeros(shape=nbin)\n",
    "        n_tot    = np.zeros(shape=nbin)\n",
    "        eta      = np.zeros(shape=nbin)\n",
    "        snow_ext = np.zeros(shape=nbin)\n",
    "        IWC      = np.zeros(shape=nbin)\n",
    "        mind     = np.zeros(shape=(nbin,nd))\n",
    "        \n",
    "        Ze_ss            = np.zeros(shape=nbin)       # singly-scattered nonattenuated reflectivity Zess,na\n",
    "        Ze_ss_atten      = np.zeros(shape=nbin)       # singly-scattered attenuated reflectivity Zess,a \n",
    "        Ze_fin           = np.zeros(shape=nbin)\n",
    "        Ze_multiple_scat = np.zeros(shape=nbin)\n",
    "        y_sim            = np.zeros(shape=nbin)       # simulated refelectivities\n",
    "        snow_ext_accum = 0.0\n",
    "# line 106:\n",
    "# for i=0,nbin-1 do begin\n",
    "#    lamb(i)=10^slp2(i)\n",
    "#    n0(i)=10^slp2(i+nbin)\n",
    "        for j in range(0,nbin):\n",
    "            lamb[j] = (10.**(slp2[j]))\n",
    "            N0[j]   = (10**(slp2[j+nbin]))\n",
    "\n",
    "# line 117:\n",
    "# for j=0,nbin-1 do begin             ; each vertical radar bin \n",
    "#      for i=0,nd-1 do begin\n",
    "#           numd(i)=n0(j)*exp(-lamb(j)*ldim(i))          ;   per (m^3 mm) \n",
    "        for j in range(0,nbin):\n",
    "            for i in range(0, nd):\n",
    "                numd[i] = (N0[j]*math.exp( (- lamb[j] * Ldim[i])) )     # size distribution n(D) = n0 exp(-lambda*D)\n",
    "                \n",
    "##############################################\n",
    "\n",
    "#### INTEGRATE TO FIND IWP/SWC IN EACH LAYER/RADAR BIN BASED UPON PSD ###########################\n",
    "# line 124:\n",
    "# iwcpsd(j)=numd(0)*mass(0)*(ldim(0)-0.)/2.\n",
    "# for i=0,nd-2 do begin\n",
    "#    iwcpsd(j)=iwcpsd(j)+(numd(i)*mass(i)+numd(i+1)*mass(i+1))*(ldim(i+1)-ldim(i))/2.0\n",
    "# iwcpsd(j)=iwcpsd(j)+numd(nd-1)*mass(nd-1)*(ldim(nd-1)-ldim(nd-2))/2.\n",
    "        \n",
    "            IWC_psd[j] = ((numd[0]*mass[0]) * (Ldim[0]-0.)/2.)\n",
    "#            fx = numd*mass\n",
    "            for i in range(0,nd-1):\n",
    "                IWC_psd[j] = (IWC_psd[j] + (numd[i]*mass[i] + numd[i+1]*mass[i+1]) * (Ldim[i+1] - Ldim[i])/2.)\n",
    "            IWC_psd[j] = (IWC_psd[j] + (numd[nd-1]*mass[nd-1]) * (Ldim[nd-1] - Ldim[nd-2])/2.)\n",
    "            \n",
    "\n",
    "#            IWC_psd = integration_layer_bin(IWC_psd, j, numd*mass, Ldim, nd)      # ice water content\n",
    "##############################################\n",
    "\n",
    "#### INTEGRATE TO FIND NUMBER, EXTINCTION, BACKSCATTER, ETC ###########################\n",
    "# line 136:\n",
    "# nt(j)=numd(0)*(ldim(0)-0.)/2.\n",
    "# for i=0,nd-2 do begin\n",
    "#    nt(j)=nt(j)+(numd(i)+numd(i+1))*(ldim(i+1)-ldim(i))/2.0\n",
    "# nt(j)=nt(j)+numd(nd-1)*(ldim(nd-1)-ldim(nd-2))/2.\n",
    "            n_tot    = integration_layer_bin(n_tot, j, numd, Ldim,nd)           # total number concentration\n",
    "            eta      = integration_layer_bin(eta, j, numd*C_bk, Ldim, nd)       # \n",
    "            snow_ext = integration_layer_bin(snow_ext, j, numd*C_ext, Ldim, nd) #\n",
    "            IWC      = integration_layer_bin(IWC, j, numd*mass, Ldim, nd)       # ice water content\n",
    "#            n_tot[j]    = numd[0]* (Ldim[0]-0.)/2.\n",
    " #           eta[j]      = (numd[0]*C_bk[0]) * (Ldim[0]-0.)/2.\n",
    "  #          snow_ext[j] = (numd[0]*C_ext[0])* (Ldim[0]-0.)/2.\n",
    "   #         IWC[j]      = (numd[0]*mass[0]) * (Ldim[0]-0.)/2.\n",
    "            \n",
    "            mind[j,0] = numd[0]*mass[0] * (Ldim[0]-0.)/2.\n",
    "            for i in range(0,nd-1):\n",
    "      #          n_tot[j]    = n_tot[j]    + (numd[i]         + numd[i+1])          *(Ldim[i+1] - Ldim[i])/2.\n",
    "       #         eta[j]      = eta[j]      + (numd[i]*C_bk[i] + numd[i+1]*C_bk[i+1]) *(Ldim[i+1] - Ldim[i])/2.0\n",
    "        #        snow_ext[j] = snow_ext[j] + (numd[i]*C_ext[i] + numd[i+1]*C_ext[i+1])*(Ldim[i+1] - Ldim[i])/2.0\n",
    "         #       IWC[j]      = IWC[j]      + (numd[i]*mass[i] + numd[i+1]*mass[i+1]) *(Ldim[i+1]-Ldim[i])/2.0\n",
    "\n",
    "                mind[j,i] = np.trapz(numd[i:i+2]*mass[i:i+2], Ldim[i:i+2])\n",
    "           \n",
    "           # n_tot[j]    = n_tot[j]    + numd[nd-1] * (Ldim[nd-1] - Ldim[nd-2])/2.\n",
    "            #eta[j]      = eta[j]      + (numd[nd-1]*C_bk[nd-1]) *(Ldim[nd-1] - Ldim[nd-2])/2.\n",
    " #           snow_ext[j] = snow_ext[j] + (numd[nd-1]*C_ext[nd-1])*(Ldim[nd-1] - Ldim[nd-2])/2.\n",
    "  #          IWC[j]      = IWC[j]      + (numd[nd-1]*mass[nd-1]) *(Ldim[nd-1] - Ldim[nd-2])/2.\n",
    "            \n",
    "            mind[j,i] = numd[nd-1]*mass[nd-1] * (Ldim[nd-1] - Ldim[nd-2])/2.\n",
    "##############################################\n",
    "\n",
    "#### ACCOUNT FOR ATTENUATION THROUGH LAYERS WITHIN RADAR BINS ###########################\n",
    "# line 162:\n",
    "# snow_ext_accum = snow_ext_accum + snowext(j)*deltaz*1.0        ; 1.0 here is a scaling factor\n",
    "            snow_ext_accum   = snow_ext_accum + snow_ext[j]*dz*1.0        # 1. is scaling factor\n",
    "            snow_attenuation = np.exp(-snow_ext_accum)                    # Beer's law exp (−β*s)\n",
    "# line 168:\n",
    "# Ze_ss(j) = eta(j)*waveln_mm^4.0/(k_sq_water*pi^5.0)*1e6       ; from Norm 2015? Eq. 15?\n",
    "# Ze_ss_atten(j) = Ze_ss(j)*snow_atten*snow_atten               ; 2 way attenuation\n",
    "# Ze_fin(j)=10.*alog10(ze_ss_atten(j))\n",
    "\n",
    "            \n",
    "           # print(wavel_mm, K_sq_water)\n",
    "            ## Wood, 2C-SNOW-PROFILE Eq. 17, 19\n",
    "            Ze_ss[j]       = (eta[j]*wavel_mm**4)/ (K_sq_water*const.pi**5)*10**6   # singly-scattered nonattenuated reflectivity Zess,na at range bin i\n",
    "            Ze_ss_atten[j] = Ze_ss[j] * snow_attenuation**2                         # singly-scattered attenuated reflectivity Zess,a \n",
    "            Ze_fin[j]      = 10.*math.log10(Ze_ss_atten[j])       ## in [dBZ]\n",
    "##############################################\n",
    "\n",
    "#### USE THE GEOMETRIC MEAN OF Ze_ss, Ze_ss_ext TO ESTIMATE THE MULTIPLE SCATTERED Ze ###########################\n",
    "#### GIVES dBZe HALFWAY BETWEEN THE TWO ###########################\n",
    "#### SEE MATROSOV AND BATTAGLIA, (2009), AND WOOD (2011, DISSERTATION, SEC. 7.2, 7.3.1)\n",
    "# line 180:\n",
    "# Ze_ms(j) = 10.*alog10(sqrt(Ze_ss(j)*Ze_ss_atten(j)))\n",
    "# y_sim(j) = Ze_fin(j)\n",
    "\n",
    "            Ze_multiple_scat[j] = 10.*math.log10(np.sqrt(Ze_ss[j]*Ze_ss_atten[j]))  ## in [dBZ]\n",
    "            y_sim = Ze_fin                                                          ## simulated reflectivities in [dBz]\n",
    "        \n",
    "        #    print(Ze_multiple_scat[j])\n",
    "##############################################\n",
    "    return(y_sim,IWC_psd);\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def integration_layer_bin(variable, i, fx, dx, nd):\n",
    "    variable[i] = ((fx[0]) * (dx[0]-0.)/2.)\n",
    "    for j in range(0,nd-1):\n",
    "    #   IWC_psd[i] = (IWC_psd[i] + (numd[j]*mass[j] + numd[j+1]*mass[j+1]) * (Ldim[j+1] - Ldim[j])/2.)\n",
    "        variable[i] = (variable[i] + np.trapz(fx[j:j+2],dx[j:j+2]))\n",
    "    variable[i] = (variable[i] + (fx[nd-1]) * (dx[nd-1] - dx[nd-2])/2.)\n",
    "    return(variable);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################\n",
    "######## the following is not in the retrieval just to plot the case  y_obs > -15., surftemp < 2.##################   \n",
    "list1 = (np.where(np.isnan(h_snow)))\n",
    "list1 = np.asarray(list1)\n",
    "\n",
    "list2 = []\n",
    "list2.append(list1[0,0])\n",
    "for i in range(0,list1.shape[1]-1):\n",
    "    if (list1[0,i+1] - list1[0,i] > 1):\n",
    "        list2.extend([list1[0,i], list1[0,i+1]])\n",
    "list2 = np.asarray(list2)\n",
    "\n",
    "idx2 = []\n",
    "for i in range(0,list2.shape[0]-1,2):\n",
    "    if (list2[i+1] - list2[i] >=40):\n",
    "        idx2.extend([list2[i], list2[i+1]])\n",
    "\n",
    "for k in range(0, np.asarray(idx2).shape[0],2):\n",
    "    for i in range(idx2[k],idx2[k+1]):\n",
    "        h_snow[i] = 1\n",
    "\n",
    "### plot reflectivity\n",
    "fig = plt.figure(figsize=(20,7))\n",
    "gs = gridspec.GridSpec(7,1)\n",
    "ax0 = fig.add_subplot(gs[:6,:])\n",
    "plt_refl(ax0, time_MRR, height_MRR, np.transpose(Ze), calday, day, calmon, year)\n",
    "\n",
    "\n",
    "\n",
    "for k in range(0, np.asarray(idx2).shape[0],2):\n",
    "    dots = ax0.plot(np.asarray(time_MRR)[idx2[k]:idx2[k+1]],np.asarray(h_snow)[idx2[k]:idx2[k+1]],color='purple',\n",
    "                   linestyle='-',linewidth=5)\n",
    "    dots2 = ax0.plot(np.asarray(time_MRR)[idx2[k]:idx2[k+1]],2998.+np.asarray(h_snow)[idx2[k]:idx2[k+1]],color='purple',\n",
    "                   linestyle='-',linewidth=5)\n",
    "    ax0.axvline(np.asarray(time_MRR)[idx2[k]], color='purple', linestyle='-',linewidth=5)\n",
    "    ax0.axvline(np.asarray(time_MRR)[idx2[k+1]], color='purple', linestyle='-',linewidth=5)\n",
    "\n",
    "if sfig == 1:\n",
    "    fig_name = 'MRR_%s%s%s.%s' %(year,mon,day,form)\n",
    "    SF.save_figure_landscape(fig_dir, fig_name, form)\n",
    "else:\n",
    "    plt.show()\n",
    "plt.close()\n",
    "#################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
