{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.quora.com/How-can-a-standard-deviation-divided-by-mean-be-useful \n",
    "\n",
    "The coefficient of variation (CV), defined as Standard deviation (SD) divided by the Mean describes the variability of a sample relative to its mean. Because the CV is unitless and usually expressed as a percentage, it is used instead of the SD to compare the spread of data sets that have different units of measurements or have the same units of measurements but differs greatly in magnitude.\n",
    "\n",
    "Let’s say you’re comparing the weights of mice and rabbits. You determine from a sample that the average weight of mice is 1 ounce with a SD of 0.08 ounces, whereas the mean weight of rabbits is 16 ounces with a SD of 0.4 ounces.\n",
    "\n",
    "Although the SD of the rabbits is five times greater than the SD of the mice, their CVs support a different conclusion:\n",
    "\n",
    "•\tRabbits: CV = 100 * 0.4 ounces / 16 ounces = 2.5 %\n",
    "\n",
    "•\tMice: CV = 100 * 0.08 ounces / 1 ounce = 8 %\n",
    "\n",
    "•\tThe CV of mice is more than three times greater than that of the rabbits. In other words, although rabbits have a greater SD, mice have much more weight variability relative to their mean.\n",
    "\n",
    "For variables measured in different units (let’s say you want to compare weight measured in ounces and length measured in inches) it provides a simple way to compare oranges to apples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Volumes/SANDISK128/Documents/Thesis/Python/')\n",
    "sys.path.append('/Volumes/SANDISK128/Documents/Thesis/Python/weather_mast/')\n",
    "sys.path.append('/Volumes/SANDISK128/Documents/Thesis/Python/Retrieval/')\n",
    "import netCDF4\n",
    "import fill_values as fv\n",
    "import datetime\n",
    "import calc_date as cd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import save_fig as sF\n",
    "import createFolder as cF\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import plt_ce_image as im\n",
    "import read_MRR as pMRR\n",
    "import plot_sfc_spaghetti_ret as spagh\n",
    "\n",
    "from scipy.integrate import simps\n",
    "\n",
    "#plt.style.use('ggplot')\n",
    "##plt.style.use('classic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = '2016'\n",
    "month = '12'\n",
    "#t = ['17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27']\n",
    "t = ['20', '21', '22', '23', '24', '25', '26', '27']\n",
    "tid = '00'\n",
    "station = 'Haukeliseter'\n",
    "\n",
    "\n",
    "### Figures \n",
    "savefig = 0\n",
    "figdir = '../../Figures/Retrieval_MEPS/coefficent_variation/_48'\n",
    "cF.createFolder('%s/' %(figdir))\n",
    "form = 'png'\n",
    "################################################################\n",
    "### MEPS\n",
    "level = 'sfc'\n",
    "nc_dir_sfc = '../../Data/MEPS/%s/%s_%s' %(station,level,tid)\n",
    "level = 'ml'\n",
    "nc_dir_ml = '../../Data/MEPS/%s/%s_%s' %(station,level,tid)\n",
    "# air temperature\n",
    "var_name_air_temp = 'air_temperature_ml'\n",
    "air_temp_dir = '%s/%s' %(nc_dir_ml,var_name_air_temp)\n",
    "# snow fall amount\n",
    "var_name_snow = 'snowfall_amount_ml'\n",
    "snow_dir = '%s/%s' %(nc_dir_ml,var_name_snow)\n",
    "# graupel fall amount\n",
    "var_name_graupel = 'graupelfall_amount_ml'\n",
    "graupel_dir = '%s/%s' %(nc_dir_ml,var_name_graupel)\n",
    "# atmosphere_cloud_ice_content_ml\n",
    "var_name_cl_ice = 'atmosphere_cloud_ice_content_ml'\n",
    "cl_ice_dir = '%s/%s' %(nc_dir_ml,var_name_cl_ice)\n",
    "\n",
    "################################################################\n",
    "### MRR\n",
    "MRR_dir = '../../Data/MRR/processed_MRR'\n",
    "\n",
    "################################################################\n",
    "### Retrieval \n",
    "nc_dir_retrieval = '../../Data/Retrieved_SWC'\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MRR ######\n",
    "fnMRR      = dict()\n",
    "time_MRR   = dict()\n",
    "height_MRR = dict()\n",
    "Ze         = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## RETRIEVAL ######\n",
    "fnRet      = dict()\n",
    "retrieved_snowfall_amount = dict()\n",
    "SWC        = dict()\n",
    "SWP_ret    = dict() \n",
    "SWC_con    = dict()\n",
    "time_con   = dict()\n",
    "SWP_mean_ret= dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_temp_file     = dict()\n",
    "snow_file         = dict()\n",
    "graupel_file      = dict()\n",
    "cl_ice_file       = dict()\n",
    "\n",
    "fn_air_temp       = dict()\n",
    "fn_snow           = dict()\n",
    "fn_graupel        = dict()\n",
    "fn_cl_ice         = dict()\n",
    "\n",
    "time_ml           = dict()\n",
    "air_temp_ml       = dict()\n",
    "pressure_ml       = dict()\n",
    "snow_amount_ml    = dict()\n",
    "graupel_amount_ml = dict()\n",
    "cl_ice_ml         = dict()\n",
    "\n",
    "thickness_ml      = dict()\n",
    "ice_amount_ml     = dict()\n",
    "time              = dict()\n",
    "height_ml         = dict()\n",
    "height            = dict()\n",
    "density_ml        = dict()\n",
    "SWP_model         = dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rd = 287.    # gas constant for dry air [J kg^-1 K^-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer for average snow water content within 200 m\n",
    "nlay= 15\n",
    "bot = []\n",
    "top = []\n",
    "for k in range(0, nlay):\n",
    "    bot.append(100.+ k*200)\n",
    "    top.append(bot[k]+200)\n",
    "\n",
    "avg_SWC_ml = dict()\n",
    "h_avg      = dict()\n",
    "t_avg      = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_coeff_vari(t_avg, h_avg,std_mean,ice_mean):\n",
    "    fig = plt.figure(1, figsize=(20,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    # Vertical line to show end of day\n",
    "    ax.axvline(0,color = spagh.vert_col, linewidth = 3)\n",
    "    ax.axvline(24,color = spagh.vert_col, linewidth = 3)\n",
    "    ax.axvline(48,color = spagh.vert_col, linewidth = 3)\n",
    "\n",
    "\n",
    "    v_min=0.\n",
    "    xticks=np.arange(0,49,3)\n",
    "    yticks=im.yticks1\n",
    "    xlabel=xdays\n",
    "    \n",
    "\n",
    "    levels3 = [0, 25, 50, 75, 100]\n",
    "    im0 = ax.contourf((t_avg), (h_avg),\n",
    "                      (std_mean),levels3,\n",
    "                      #cmap='seismic', extend = 'max', \n",
    "                      cmap='magma', extend = 'max', \n",
    "                      alpha = 1.0, \n",
    "                       vmin = v_min, vmax = 100., origin = 'lower')\n",
    "    \n",
    "    \n",
    "\n",
    "    levels2 = np.arange(0,1.41,0.1)\n",
    "    cth = ax.contour((t_avg), (h_avg),(ice_mean), \n",
    "                     levels2, colors= 'grey', \n",
    "                linewidths=2.)\n",
    "    plt.clabel(cth, fontsize = 18., inline=1, fmt = '%0.1f')\n",
    "\n",
    "# set the limits of the plot to the limits of the data\n",
    "    ax.axis([0., 49, 0., 3000])\n",
    "\n",
    "# labels \n",
    "    im.labels_x(ax,xticks,xlabel)\n",
    "    im.labels_y(ax,yticks,im.yl1,'height [km]')\n",
    "# add colorbar   \n",
    "    cbar =fig.colorbar(im0,orientation ='horizontal',pad=0.3, ticks = levels3,#shrink=0.8,\n",
    "                       aspect=40)\n",
    "    cbar.ax.tick_params(labelsize = im.tick_fs-2)\n",
    "    cbar.ax.set_xlabel('coefficient of variation [%]', fontsize=im.label_fs-2)\n",
    "    \n",
    "    labels = ['ensemble mean']\n",
    "    for i in range(len(labels)):\n",
    "        cth.collections[i].set_label(labels[i])\n",
    "\n",
    "    lgd = ax.legend(loc='upper left',fontsize=im.label_fs)\n",
    "    frame = lgd.get_frame()\n",
    "    frame.set_facecolor('white')\n",
    "\n",
    "    \n",
    "# title\n",
    "    title = 'initalised: %s, %s %s %s %s UTC' %(calday,ini_day,calmon,year,hh)\n",
    "    ax.set_title(title, fontsize=im.fontsize, color =im.date_blue )\n",
    "# tight layout\n",
    "    fig.tight_layout()#pad=1.4,  h_pad=2.5)\n",
    "    fig.subplots_adjust(top=0.94)  \n",
    "    \n",
    "    return(cbar);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(0,np.asarray(t).shape[0]):\n",
    "#for k in range(3,4):\n",
    "    day = t[k]\n",
    "## MEPS ######\n",
    "    for ens_memb in range(0,10):\n",
    "        air_temp_file[ens_memb]= '%s/%s%s%s_%s_%s.nc' %(air_temp_dir,year,month,day,tid,ens_memb)\n",
    "        snow_file[ens_memb]    = '%s/%s%s%s_%s_%s.nc' %(snow_dir,year,month,day,tid,ens_memb)\n",
    "        graupel_file[ens_memb] = '%s/%s%s%s_%s_%s.nc' %(graupel_dir,year,month,day,tid,ens_memb)\n",
    "        cl_ice_file[ens_memb]  = '%s/%s%s%s_%s_%s.nc' %(cl_ice_dir,year,month,day,tid,ens_memb)\n",
    "        \n",
    "        fn_air_temp[ens_memb]  = netCDF4.Dataset(air_temp_file[ens_memb])\n",
    "        fn_snow[ens_memb]      = netCDF4.Dataset(snow_file[ens_memb])\n",
    "        fn_graupel[ens_memb]   = netCDF4.Dataset(graupel_file[ens_memb]) \n",
    "        fn_cl_ice[ens_memb]    = netCDF4.Dataset(cl_ice_file[ens_memb])\n",
    "\n",
    "# Read in time to know initialisation time (plotting)    \n",
    "        time_ml[ens_memb] = fn_snow[ens_memb].variables['time']\n",
    "        time_ml[ens_memb] = fv.fill_nan(time_ml[ens_memb][:])\n",
    "        \n",
    "\n",
    "        ini_day = datetime.datetime.utcfromtimestamp(time_ml[0][0]).day   # day of initialisation\n",
    "        hh = datetime.datetime.utcfromtimestamp(time_ml[0][0]).hour       # first hour of initialisation?\n",
    "        calday, calmon = cd.get_dayname(year, month, ini_day)\n",
    "        \n",
    "# Read in the pressure, and the air temperature to calculate ice amount from [kg/kg] to [kg/m^3]\n",
    "        air_temp_ml[ens_memb] = fn_air_temp[ens_memb].variables[var_name_air_temp]\n",
    "        pressure_ml[ens_memb] = fn_snow[ens_memb].variables['pressure_ml']\n",
    "# Read in the variable name which should be plotted  \n",
    "        snow_amount_ml[ens_memb]    = fn_snow[ens_memb].variables[var_name_snow]\n",
    "        graupel_amount_ml[ens_memb] = fn_graupel[ens_memb].variables[var_name_graupel]\n",
    "        cl_ice_ml[ens_memb]         = fn_cl_ice[ens_memb].variables[var_name_cl_ice]\n",
    "\n",
    "\n",
    "# create an array with time of the shape of the variable\n",
    "        lead_time   = np.arange(0,snow_amount_ml[ens_memb].shape[0])\n",
    "        model_level = np.arange(0,snow_amount_ml[ens_memb].shape[1])\n",
    "        td,Y        = np.meshgrid(lead_time,model_level)\n",
    "\n",
    "# substitute missing values with nan \n",
    "        pressure_ml[ens_memb]       = fv.fill_nan(pressure_ml[ens_memb][:])\n",
    "        air_temp_ml[ens_memb]       = fv.fill_nan(air_temp_ml[ens_memb][:])\n",
    "        snow_amount_ml[ens_memb]    = fv.fill_nan(snow_amount_ml[ens_memb][:])\n",
    "        graupel_amount_ml[ens_memb] = fv.fill_nan(graupel_amount_ml[ens_memb][:])\n",
    "        cl_ice_ml[ens_memb]         = fv.fill_nan(cl_ice_ml[ens_memb][:])\n",
    "# get ice amount (snow+graupel)\n",
    "        ice_amount_ml[ens_memb]     = snow_amount_ml[ens_memb] + graupel_amount_ml[ens_memb] + cl_ice_ml[ens_memb]\n",
    "\n",
    "    \n",
    "# layer thickness to calculate height\n",
    "        thickness_ml[ens_memb]      = fn_snow[ens_memb].variables['layer_thickness']\n",
    "        thickness_ml[ens_memb]      = fv.fill_nan(thickness_ml[ens_memb][:])\n",
    "    \n",
    "        thickness = thickness_ml[ens_memb]\n",
    "        h_above = []\n",
    "        h_above.append(np.zeros(thickness[:,:].shape[0]))\n",
    "        th_arr = np.nansum([np.asarray(h_above)[:,0], thickness[:,0]], axis = 0)\n",
    "        h_above.append(th_arr)\n",
    "        for i in range(2,thickness[:,:].shape[1]):\n",
    "            th_arr = np.nansum([h_above[i-1], thickness[:,i-1]], axis = 0)\n",
    "            h_above.append(th_arr)\n",
    "        height_ml[ens_memb] = np.transpose(h_above) \n",
    "        \n",
    "        \n",
    "####\n",
    "# calculate density at each level\n",
    "        density_ml[ens_memb] = pressure_ml[ens_memb]/(Rd*air_temp_ml[ens_memb])\n",
    "              \n",
    "\n",
    "# convert from [kg/kg] to [kg/m^3]\n",
    "        ice_amount_ml[ens_memb] = (ice_amount_ml[ens_memb]*density_ml[ens_memb])\n",
    "\n",
    "# convert the snow amount from [kg/m^2] into [g/m^2] by multiply with 1000\n",
    "        ice_amount_ml[ens_memb] = (ice_amount_ml[ens_memb]*1000.)\n",
    "    \n",
    "    \n",
    "# calculate mean of snowfall amount in each layer, every 200m\n",
    "        SWC_ml = []\n",
    "        h_mid = []\n",
    "        for k in range(0, nlay):\n",
    "            tidx,hidx = np.where(np.logical_and(height_ml[ens_memb][:,:] >= bot[k], height_ml[ens_memb][:,:] < top[k]))\n",
    "# average in layer\n",
    "            SWC_ml.append(np.nanmean(ice_amount_ml[ens_memb][:,hidx[:]], axis = 1))\n",
    "            h_mid.append((bot[k]+top[k])/2)\n",
    "        avg_SWC_ml[ens_memb] = SWC_ml      \n",
    "        \n",
    "        time[ens_memb]          = td\n",
    "        height[ens_memb]        = height_ml[ens_memb]   \n",
    "        \n",
    "        hidx = []\n",
    "        tidx = []\n",
    "        for i in range(0,np.asarray(avg_SWC_ml[ens_memb]).shape[1]):\n",
    "            hidx.append(h_mid)\n",
    "        h_avg[ens_memb] = hidx\n",
    "        for i in range(0,np.asarray(avg_SWC_ml[ens_memb]).shape[0]):\n",
    "            tidx.append(time[ens_memb][0,:])\n",
    "        t_avg[ens_memb] = tidx\n",
    "        \n",
    "        \n",
    "## only use values below 3km\n",
    "        h1, h2 = np.where(height[ens_memb][:,:] > 3000)\n",
    "        ice_amount_ml[ens_memb][h1[:],h2[:]] = np.nan\n",
    "        time[ens_memb][h2[:],h1[:]]          = -9999\n",
    "        height[ens_memb][h1[:],h2[:]]        = np.nan\n",
    "        \n",
    "        \n",
    "               \n",
    "\n",
    "#    print('%s, %s %s %s' %(calday, day, calmon, year))\n",
    " #   # retrieval \n",
    "  #  r1, r2 = np.where(mean_SWC[day] == np.nanmax(mean_SWC[day] ))\n",
    "   # if len(r1) == 0 or len(r2) == 0:\n",
    "    #    print('max SWC in retrieval: NaN')\n",
    "#    else: \n",
    " #       print('max SWC in retrieval: %.2f kg m^-3 in %.1f m; @ %.02d UTC' %(np.nanmax(mean_SWC[day]),height_MRR[day][r1],r2))\n",
    "    \n",
    "\n",
    "#    # MEPS\n",
    " #   ml1, ml2 = np.where(np.transpose(avg_SWC_ml[0]) == np.nanmax(np.transpose(avg_SWC_ml[0])[:25,:] ))\n",
    "  #  if len(ml1) == 0 or len(ml2) == 0:\n",
    "   #     print('max SWC in ml       : NaN')\n",
    "    #else:\n",
    "     #   print('max SWC in ml 0th EM: %.2f kg m^-3 in %.1f m; @ %.02d UTC' %(np.nanmax(np.transpose(avg_SWC_ml[0])[:25,:]), \n",
    "      #                                                                      np.asarray(h_avg[0])[ml1,ml2], \n",
    "       #                                                                     datetime.datetime.utcfromtimestamp(time_ml[0][ml1]).hour))\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "#    val = np.zeros(shape=(10,np.asarray(avg_SWC_ml[0]).shape[0]))\n",
    " #   ice_mean = []\n",
    "  #  SWP_mean_ml = []\n",
    "   # ice_std = []\n",
    "    #variable = []\n",
    "# calculate the ensemble mean of ice amount (all 10 ensemble member averaged)\n",
    "#    for k in range(0,ice_amount_ml[0].shape[0]):\n",
    "\n",
    "#        for ens_memb in range(0,10):\n",
    " #           val[ens_memb] = (np.transpose(avg_SWC_ml[ens_memb])[k,:])\n",
    "\n",
    "\n",
    "  #      variable.append(val)\n",
    "    ### std, mean\n",
    "   #     ice_std.append(np.nanstd(val,axis=0,ddof=1))  \n",
    "    #    ice_mean.append(np.nanmean(val,axis=0))\n",
    "###### HOURLY EM0,1 ######    \n",
    "    val = np.zeros(shape=(10,np.asarray(avg_SWC_ml[0]).shape[0]))\n",
    "    ice_mean_1h = []\n",
    "    ice_std_1h = []\n",
    "    for k in range(0,ice_amount_ml[0].shape[0]):\n",
    "        for ens_memb in range(0,2):\n",
    "            val[ens_memb] = (np.transpose(avg_SWC_ml[ens_memb])[k,:])\n",
    "\n",
    "            \n",
    "    ### std, mean hourly\n",
    "        ice_std_1h.append(np.nanstd(val,axis=0,ddof=1))  \n",
    "        ice_mean_1h.append(np.nanmean(val,axis=0))\n",
    "\n",
    "        \n",
    "\n",
    "###### 3 HOURLY EM0-EM9 ######    \n",
    "    val = np.zeros(shape=(10,np.asarray(avg_SWC_ml[0]).shape[0]))\n",
    "    ice_mean_3h = []\n",
    "    ice_std_3h = []\n",
    "    for k in range(0,ice_amount_ml[0].shape[0],3):\n",
    "        for ens_memb in range(0,10):\n",
    "            if ens_memb == 0 or ens_memb == 1:\n",
    "                val[ens_memb] = (np.transpose(avg_SWC_ml[ens_memb])[k,:])\n",
    "            else:\n",
    "                val[ens_memb] = (np.transpose(avg_SWC_ml[ens_memb])[k,:])\n",
    "            \n",
    "    ### std, mean 3 hourly\n",
    "        ice_std_3h.append(np.nanstd(val,axis=0,ddof=1))  \n",
    "        ice_mean_3h.append(np.nanmean(val,axis=0))\n",
    "        \n",
    "###### HOURLY with nan EM0-EM9 ######    \n",
    "    val = np.zeros(shape=(10,np.asarray(avg_SWC_ml[0]).shape[0]))\n",
    "    ice_mean_EM = []\n",
    "    ice_std_EM = []\n",
    "    for k in range(0,ice_amount_ml[0].shape[0]):\n",
    "        for ens_memb in range(0,10):\n",
    "            val[ens_memb] = (np.transpose(avg_SWC_ml[ens_memb])[k,:])\n",
    "            \n",
    "    ### std, mean hourly\n",
    "        ice_std_EM.append(np.nanstd(val,axis=0,ddof=1))  \n",
    "        ice_mean_EM.append(np.nanmean(val,axis=0))\n",
    "\n",
    "### set ice mean values smaller zero to nan ###\n",
    "    ### HOURLY EM0-EM2 ###\n",
    "    if len(ice_mean_1h) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        a4,b4 = np.where(np.asarray(ice_mean_1h) < 0.0)\n",
    "        ice_mean_1h = np.asarray(ice_mean_1h)\n",
    "        ice_mean_1h[a4[:],b4[:]] = np.nan\n",
    "    ### standard deviation over mean: ######\n",
    "    std_mean_1h = 100.*np.asarray(ice_std_1h)/np.asarray(ice_mean_1h)\n",
    "    \n",
    "    ### 3 HOURLY EM0-EM9 ###\n",
    "    if len(ice_mean_3h) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        a4,b4 = np.where(np.asarray(ice_mean_3h) < 0.0)\n",
    "        ice_mean_3h = np.asarray(ice_mean_3h)\n",
    "        ice_mean_3h[a4[:],b4[:]] = np.nan\n",
    "    ### standard deviation over mean: ######\n",
    "    std_mean_3h = 100.*np.asarray(ice_std_3h)/np.asarray(ice_mean_3h)\n",
    "    \n",
    "    ### HOURLY EM0-EM9 ###\n",
    "    if len(ice_mean_EM) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        a4,b4 = np.where(np.asarray(ice_mean_EM) < 0.0)\n",
    "        ice_mean_EM = np.asarray(ice_mean_EM)\n",
    "        ice_mean_EM[a4[:],b4[:]] = np.nan\n",
    "    ### standard deviation over mean: ######\n",
    "    std_mean_EM = 100.*np.asarray(ice_std_EM)/np.asarray(ice_mean_EM)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#MEPS\n",
    "#    ml11, ml22 = np.where((ice_std) == np.nanmax(np.asarray(ice_std)[:Xmax+1,:] ))\n",
    " #   if len(ml1) == 0 or len(ml2) == 0:\n",
    "  #      print('max std SWC in ml    : NaN')\n",
    "   # else:\n",
    "    #    print('max std SWC in ml    : %.2f kg m^-3 in %.1f m; @ %.02d UTC' %(np.nanmax(np.asarray(ice_std)[:Xmax+1]), \n",
    "     #                                                                        np.asarray(h_avg[0])[ml11,ml22], \n",
    "      #                                                                       datetime.datetime.utcfromtimestamp(time_ml[0][ml11]).hour))\n",
    "\n",
    "#    ml101, ml202 = np.where((ice_mean) == np.nanmax(np.asarray(ice_mean)[:Xmax+1,:] ))\n",
    " #   if len(ml101) == 0 or len(ml202) == 0:\n",
    "  #      print('max mean SWC in ml   : NaN')\n",
    "   # else:\n",
    "    #    print('max mean SWC in ml   : %.2f kg m^-3 in %.1f m; @ %.02d UTC' %(np.nanmax(np.asarray(ice_mean)[:Xmax+1]), \n",
    "     #                                                                        np.asarray(h_avg[0])[ml101,ml202], \n",
    "      #                                                                       datetime.datetime.utcfromtimestamp(time_ml[0][ml101]).hour))\n",
    "#    ml3, ml4 = np.where((std_mean) == np.nanmax(np.asarray(std_mean)[:Xmax+1,:] ))\n",
    " #   if len(ml3) == 0 or len(ml4) == 0:\n",
    "  #      print('max std/mean in ml   : NaN')\n",
    "   # else:\n",
    "    #    print('max std/mean in ml   : %.2f  %.1f m; @ %.02d UTC' %(np.nanmax(np.asarray(std_mean)[:Xmax+1]), \n",
    "     #                                                                        np.asarray(h_avg[0])[ml3,ml4], \n",
    "      #                                                                       datetime.datetime.utcfromtimestamp(time_ml[0][ml3]).hour))\n",
    "\n",
    "\n",
    "\n",
    "#    ml13, ml23 = np.where((ice_mean) == np.nanmax(np.asarray(ice_std)[:25,:] ))\n",
    " #   if len(ml1) == 0 or len(ml2) == 0:\n",
    "  #      print('max std in ml EM     : NaN')\n",
    "   # else:\n",
    "    #    print('max std in ml EM mean: %.2f kg m^-3 in %.1f m; @ %.02d UTC' %(np.nanmax(np.asarray(ice_std)[:25,:]), \n",
    "     #                                                                        np.asarray(h_avg[0])[ml11,ml22], \n",
    "      #                                                                       datetime.datetime.utcfromtimestamp(time_ml[0][ml11]).hour))\n",
    "\n",
    "\n",
    "\n",
    "    for ens_memb in range(0,10):\n",
    "        if len(ice_amount_ml[ens_memb]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            a2,b2 = np.where(ice_amount_ml[ens_memb][:,:] < 0.01)    ## 0.001? retrieved_snowfall_amount = iwcpsd*0.85*e-3*3600*24\n",
    "            ice_amount_ml[ens_memb][a2[:],b2[:]] = np.nan\n",
    "        if len(avg_SWC_ml[ens_memb]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            a3,b3 = np.where(np.asarray(avg_SWC_ml[ens_memb]) < 0.01)\n",
    "            avg_SWC_ml[ens_memb] = np.asarray(avg_SWC_ml[ens_memb])\n",
    "            avg_SWC_ml[ens_memb][a3[:],b3[:]] = np.nan \n",
    "            \n",
    "#            a4,b4 = np.where(np.asarray(ice_mean) < 0.01)\n",
    " #           ice_mean = np.asarray(ice_mean)\n",
    "  #          ice_mean[a4[:],b4[:]] = np.nan\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# get only valuable values not nan    \n",
    "        time_ml[ens_memb]       = (time_ml[ens_memb][~np.isnan(time_ml[ens_memb])])\n",
    "        time[ens_memb]          = (td[:,~np.isnan(avg_SWC_ml[ens_memb]).any(axis=1)])\n",
    "        height[ens_memb]        = (height_ml[ens_memb][~np.isnan(avg_SWC_ml[ens_memb]).any(axis=1),:])\n",
    "        thickness_ml[ens_memb]  = (thickness_ml[ens_memb][~np.isnan(avg_SWC_ml[ens_memb]).any(axis=1),:]) \n",
    "        air_temp_ml[ens_memb]   = (air_temp_ml[ens_memb][~np.isnan(avg_SWC_ml[ens_memb]).any(axis=1),:])\n",
    "        pressure_ml[ens_memb]   = (pressure_ml[ens_memb][~np.isnan(avg_SWC_ml[ens_memb]).any(axis=1),:])\n",
    "        avg_SWC_ml[ens_memb]    = (avg_SWC_ml[ens_memb][:,~np.isnan(avg_SWC_ml[ens_memb]).any(axis=0)])\n",
    "        \n",
    "#    time_std_1h    = np.transpose(t_avg[0])[~np.isnan(np.asarray(ice_std_1h)[:,:]).any(axis=1),0]\n",
    " #   height_std_1h  = np.asarray(h_avg[0])[~np.isnan(np.asarray(ice_std_1h)[:,:]).any(axis=1),:]      \n",
    "  #  ice_std_1h     = np.asarray(ice_std_1h)[~np.isnan(np.asarray(ice_std_1h)[:,:]).any(axis=1),:]\n",
    "    \n",
    "   # time_std_3h    = np.transpose(t_avg[0])[~np.isnan(np.asarray(ice_std_3h)[:,:]).any(axis=1),0]\n",
    "    #height_std_3h  = np.asarray(h_avg[0])[~np.isnan(np.asarray(ice_std_3h)[:,:]).any(axis=1),:]      \n",
    "#    ice_std_3h     = np.asarray(ice_std_3h)[~np.isnan(np.asarray(ice_std_3h)[:,:]).any(axis=1),:]\n",
    "\n",
    " #   time_std_EM    = np.transpose(t_avg[0])[~np.isnan(np.asarray(ice_std_EM)[:,:]).any(axis=1),0]\n",
    "  #  height_std_EM  = np.asarray(h_avg[0])[~np.isnan(np.asarray(ice_std_EM)[:,:]).any(axis=1),:]      \n",
    "   # ice_std_EM     = np.asarray(ice_std_EM)[~np.isnan(np.asarray(ice_std_EM)[:,:]).any(axis=1),:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if hh < 10:\n",
    "        hh = '0%s' %(hh)\n",
    "    else:\n",
    "        hh = '%s' %(hh)\n",
    "\n",
    "    \n",
    "### plot ###########################################\n",
    "    xdays = ['%s-%s-%s' %(year,month,ini_day), '',\n",
    "        6,'',12,'', 18,'',\n",
    "        '%s-%s-%s' %(year,month,ini_day+1), '',\n",
    "        6,'',12,'', 18,'',\n",
    "        '%s-%s-%s' %(year,month,ini_day+2)]\n",
    "    \n",
    "    \n",
    "    fig_name = '%s%s%s.%s' %(year,month,ini_day,form)\n",
    "    cbar = plt_coeff_vari(np.transpose((t_avg[0]))[:,:], \n",
    "                          np.asarray(h_avg[0])[:,:],np.asarray(std_mean_1h),ice_mean_1h)\n",
    "    if savefig ==1:\n",
    "        cF.createFolder('%s/_1h' %figdir)\n",
    "        plt.savefig('%s/_1h/%s' % (figdir, fig_name), format = form, bbox_inches='tight')\n",
    "        print('saved: %s/%s' %(figdir, fig_name))\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    cbar = plt_coeff_vari(np.transpose((t_avg[0]))[::3,:], \n",
    "                          np.asarray(h_avg[0])[::3,:],np.asarray(std_mean_3h),ice_mean_3h)\n",
    "    if savefig ==1:\n",
    "        cF.createFolder('%s/_3h' %figdir)\n",
    "        plt.savefig('%s/_3h/%s' % (figdir, fig_name), format = form, bbox_inches='tight')\n",
    "        print('saved: %s/%s' %(figdir, fig_name))\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    cbar = plt_coeff_vari(np.transpose((t_avg[0]))[:,:], \n",
    "                          np.asarray(h_avg[0])[:,:],np.asarray(std_mean_EM),ice_mean_EM)\n",
    "    if savefig ==1:\n",
    "        cF.createFolder('%s/_EM' %figdir)\n",
    "        plt.savefig('%s/_EM/%s' % (figdir, fig_name), format = form, bbox_inches='tight')\n",
    "        print('saved: %s/%s' %(figdir, fig_name))\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    for ens_memb in range(0,10):\n",
    "        fn_snow[ens_memb].close()\n",
    "        fn_air_temp[ens_memb].close() \n",
    "        fn_cl_ice[ens_memb].close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
